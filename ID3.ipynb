{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importData(path = 'tennis.csv'):\n",
    "\n",
    "    data = pd.read_csv(path, header =0 , skiprows = 0)\n",
    "    print(data.head())\n",
    "    data.target  =data['Play']\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(data):\n",
    "\n",
    "    d = data.iloc[:,-1]\n",
    "    d= d.value_counts()\n",
    "    s = 0\n",
    "    for v in d.keys():\n",
    "        p = d[v]/sum(d)\n",
    "        s-=p*np.log2(p)\n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def values(attr):\n",
    "    l = []\n",
    "    for x in attr:\n",
    "        if x not in l:\n",
    "            l.append(x)\n",
    "    return l\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IG(data, A):\n",
    "\n",
    "    Es = entropy(data)\n",
    "    val = values(data[A])\n",
    "    s_c = data[A].value_counts()\n",
    "    s_v = []\n",
    "\n",
    "    for v in range(len(val)):\n",
    "        ds = data[data[A] == val[v]]\n",
    "        s = 0\n",
    "        for res in values(data.iloc[:,-1]):\n",
    "            try:\n",
    "                pi = ds.iloc[:,-1].value_counts()[res]/len(ds)\n",
    "                s -= pi*np.log2(pi)\n",
    "            except:\n",
    "                s = 0\n",
    "        s_v.append(s)\n",
    "    for i in range(len(val)):\n",
    "        Es = Es - s_c[val[i]]*s_v[i]/sum(s_c)\n",
    "        \n",
    "    return Es\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "\n",
    "    def __init__(self, name = None, attr = None):\n",
    "        self.name = name\n",
    "        self.attr = attr\n",
    "    def call_(self):\n",
    "        return self.name\n",
    "\n",
    "def DTNode(data, features_used):\n",
    "    node = Node()\n",
    "    IGmax = 0\n",
    "    vbest = None\n",
    "    val_list = [ v for v in values(data)[:-1] if v not in features_used]\n",
    "\n",
    "    if val_list != []:\n",
    "\n",
    "        for v in val_list:\n",
    "\n",
    "            if IG(data, v) > IGmax:\n",
    "                IGmax = IG(data, v)\n",
    "                v_best = v\n",
    "        if v_best:\n",
    "            features_used.append(v_best)\n",
    "            node.name = v_best\n",
    "            node.attr = values(data[v_best])\n",
    "            return node\n",
    "        else:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def DTC(data, features_used):\n",
    "    root = DTNode(data, features_used)\n",
    "    DT_dict = {}\n",
    "    if root != None:\n",
    "        item = []\n",
    "        for attr in root.attr:\n",
    "            dataN = data[data[root.name] == attr]\n",
    "            if entropy(dataN) == 0:\n",
    "                item.append((attr, values(dataN.iloc[:, -1])[0]))\n",
    "            else:\n",
    "                dt = DTC(dataN, features_used)\n",
    "                item.append((attr, dt))\n",
    "        DT_dict[root.name] = item\n",
    "    return DT_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Outlook Temperature Humidity    Wind Play\n",
      "0     Sunny         Hot     High    Weak   No\n",
      "1     Sunny         Hot     High  Strong   No\n",
      "2  Overcast         Hot     High    Weak  Yes\n",
      "3      Rain        Mild     High    Weak  Yes\n",
      "4      Rain        Cool   Normal    Weak  Yes\n",
      "{'Outlook': [('Sunny', {'Humidity': [('High', 'No'), ('Normal', 'Yes')]}), ('Overcast', 'Yes'), ('Rain', {'Wind': [('Weak', 'Yes'), ('Strong', 'No')]})]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GOD WORLD\\AppData\\Local\\Temp\\ipykernel_18540\\3160606400.py:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  data.target  =data['Play']\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = importData('tennis.csv')\n",
    "\n",
    "# Initialize the list to keep track of features used\n",
    "features_used = []\n",
    "\n",
    "# Build the decision tree using the ID3 algorithm\n",
    "decision_tree = DTC(data, features_used)\n",
    "\n",
    "# Print or visualize the decision tree\n",
    "print(decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X1 = Rain]\n",
      " [X1 = Overcast]\n",
      "  [Yes]\n",
      "  [Yes]\n",
      " [X3 = Normal]\n",
      "  [X1 = Sunny]\n",
      "   [Yes]\n",
      "   [No]\n",
      "  [X4 = Weak]\n",
      "   [Yes]\n",
      "   [Yes]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def importData(path='tennis.csv'):\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "def gini_index(groups, classes):\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val) / size\n",
    "            score += p * p\n",
    "        gini += (1.0 - score) * (size / n_instances)\n",
    "    return gini\n",
    "\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    "\n",
    "def get_split(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            if gini < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "    return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth+1)\n",
    "\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n",
    "\n",
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        if isinstance(node['value'], str):\n",
    "            print('%s[X%d = %s]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "        else:\n",
    "            print('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), float(node['value']))))\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth*' ', node)))\n",
    "\n",
    "# Load the dataset\n",
    "data = importData('tennis.csv')\n",
    "dataset = data.values.tolist()\n",
    "\n",
    "# Define the maximum depth of the tree and the minimum number of samples required to split a node\n",
    "max_depth = 3\n",
    "min_size = 2\n",
    "\n",
    "# Build the CART decision tree\n",
    "tree = build_tree(dataset, max_depth, min_size)\n",
    "\n",
    "# Print the constructed decision tree\n",
    "print_tree(tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlook\n",
      "  Outlook = Overcast\n",
      "      [Class: Yes]\n",
      "  Outlook = Rain\n",
      "    Wind\n",
      "      Wind = Strong\n",
      "          [Class: No]\n",
      "      Wind = Weak\n",
      "          [Class: Yes]\n",
      "  Outlook = Sunny\n",
      "    Humidity\n",
      "      Humidity = High\n",
      "          [Class: No]\n",
      "      Humidity = Normal\n",
      "          [Class: Yes]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def importData(path='tennis.csv'):\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "def entropy(data):\n",
    "    target_values = data.iloc[:, -1].value_counts(normalize=True)\n",
    "    entropy_val = -sum(target_values * np.log2(target_values))\n",
    "    return entropy_val\n",
    "\n",
    "def information_gain_ratio(data, attribute):\n",
    "    # Calculate information gain\n",
    "    entropy_before_split = entropy(data)\n",
    "    values, counts = np.unique(data[attribute], return_counts=True)\n",
    "    weighted_entropy_after_split = sum([(counts[i] / len(data)) * entropy(data[data[attribute] == values[i]]) for i in range(len(values))])\n",
    "    information_gain = entropy_before_split - weighted_entropy_after_split\n",
    "\n",
    "    # Calculate split information\n",
    "    split_info = -sum((counts[i] / len(data)) * np.log2(counts[i] / len(data)) for i in range(len(values)))\n",
    "\n",
    "    # Calculate information gain ratio\n",
    "    if split_info == 0:\n",
    "        return 0  # To avoid division by zero\n",
    "    information_gain_ratio_val = information_gain / split_info\n",
    "\n",
    "    return information_gain_ratio_val\n",
    "\n",
    "def choose_attribute(data, attributes):\n",
    "    information_gain_ratios = [information_gain_ratio(data, attribute) for attribute in attributes]\n",
    "    best_attribute_index = np.argmax(information_gain_ratios)\n",
    "    return attributes[best_attribute_index]\n",
    "\n",
    "def split_data(data, attribute, value):\n",
    "    return data[data[attribute] == value]\n",
    "\n",
    "def majority_class(data):\n",
    "    return data.iloc[:, -1].mode()[0]\n",
    "\n",
    "def build_tree(data, attributes):\n",
    "    # If all instances have the same class label, return a leaf node with that class label\n",
    "    if len(np.unique(data.iloc[:, -1])) == 1:\n",
    "        return data.iloc[0, -1]\n",
    "\n",
    "    # If there are no more attributes to split on, return the majority class label\n",
    "    if len(attributes) == 0:\n",
    "        return majority_class(data)\n",
    "\n",
    "    # Choose the best attribute to split on\n",
    "    best_attribute = choose_attribute(data, attributes)\n",
    "\n",
    "    # Create a new decision tree node with the best attribute\n",
    "    tree = {best_attribute: {}}\n",
    "\n",
    "    # Remove the best attribute from the list of attributes\n",
    "    attributes = [attr for attr in attributes if attr != best_attribute]\n",
    "\n",
    "    # Split the dataset based on the values of the best attribute\n",
    "    for value in np.unique(data[best_attribute]):\n",
    "        sub_data = split_data(data, best_attribute, value)\n",
    "        subtree = build_tree(sub_data, attributes)\n",
    "        tree[best_attribute][value] = subtree\n",
    "\n",
    "    return tree\n",
    "\n",
    "def print_tree(tree, depth=0):\n",
    "    if isinstance(tree, dict):\n",
    "        for attribute, subtree in tree.items():\n",
    "            print('  ' * depth + attribute)\n",
    "            for value, sub_tree in subtree.items():\n",
    "                print('  ' * (depth+1) + '{} = {}'.format(attribute, value))\n",
    "                print_tree(sub_tree, depth + 2)\n",
    "    else:\n",
    "        print('  ' * depth + '  [Class: ' + str(tree) + ']')\n",
    "\n",
    "# Load the dataset\n",
    "data = importData('tennis.csv')\n",
    "\n",
    "# Get list of attribute names\n",
    "attributes = list(data.columns[:-1])\n",
    "\n",
    "# Build the decision tree using C4.5 algorithm\n",
    "tree = build_tree(data, attributes)\n",
    "\n",
    "# Print the decision tree\n",
    "print_tree(tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1\n",
      "  a1 = x\n",
      "    a3\n",
      "      a3 = n\n",
      "          [Class: +]\n",
      "      a3 = p\n",
      "        a4\n",
      "          a4 = e\n",
      "              [Class: -]\n",
      "          a4 = f\n",
      "              [Class: +]\n",
      "  a1 = y\n",
      "    a3\n",
      "      a3 = m\n",
      "          [Class: +]\n",
      "      a3 = n\n",
      "        a4\n",
      "          a4 = e\n",
      "              [Class: +]\n",
      "          a4 = f\n",
      "              [Class: -]\n"
     ]
    }
   ],
   "source": [
    "# Get list of attribute names\n",
    "\n",
    "import pandas as pd\n",
    "# \n",
    "# Define the data\n",
    "data = {\n",
    "    'a1': ['x', 'x', 'x', 'y', 'y', 'x', 'x', 'y', 'x', 'x', 'y', 'x'],\n",
    "    'a2': ['u', 'u', 'u', 'u', 'v', 'v', 'u', 'v', 'u', 'w', 'w', 'w'],\n",
    "    'a3': ['n', 'p', 'n', 'n', 'n', 'n', 'p', 'm', 'n', 'p', 'n', 'n'],\n",
    "    'a4': ['e', 'f', 'g', 'e', 'f', 'e', 'e', 'f', 'f', 'f', 'f', 'g'],\n",
    "    'Class': ['+', '+', '+', '+', '-', '+', '-', '+', '+', '+', '-', '+']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "attributes = list(data.columns[:-1])\n",
    "\n",
    "# Build the decision tree using C4.5 algorithm\n",
    "tree = build_tree(data, attributes)\n",
    "\n",
    "# Print the decision tree\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {'a1': 'x', 'a2': 'u', 'a3': 'n', 'a4': 'e'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day\n",
      "  Day = D1\n",
      "      [Class: No]\n",
      "  Day = D10\n",
      "      [Class: Yes]\n",
      "  Day = D11\n",
      "      [Class: Yes]\n",
      "  Day = D12\n",
      "      [Class: Yes]\n",
      "  Day = D13\n",
      "      [Class: Yes]\n",
      "  Day = D14\n",
      "      [Class: No]\n",
      "  Day = D2\n",
      "      [Class: No]\n",
      "  Day = D3\n",
      "      [Class: Yes]\n",
      "  Day = D4\n",
      "      [Class: Yes]\n",
      "  Day = D5\n",
      "      [Class: Yes]\n",
      "  Day = D6\n",
      "      [Class: No]\n",
      "  Day = D7\n",
      "      [Class: Yes]\n",
      "  Day = D8\n",
      "      [Class: No]\n",
      "  Day = D9\n",
      "      [Class: Yes]\n"
     ]
    }
   ],
   "source": [
    "# Get list of attribute names\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Day': [f'D{i}' for i in range(1, 15)],\n",
    "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],\n",
    "    'Temperature (oF)': [85, 80, 83, 70, 68, 65, 64, 72, 69, 75, 75, 72, 81, 71],\n",
    "    'Humidity (%)': [85, 90, 86, 96, 80, 70, 65, 95, 70, 80, 70, 90, 75, 91],\n",
    "    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Strong'],\n",
    "    'PlayTennis': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
    "}\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "attributes = list(data.columns[:-1])\n",
    "\n",
    "# Build the decision tree using C4.5 algorithm\n",
    "tree = build_tree(data, attributes)\n",
    "\n",
    "# Print the decision tree\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlook\n",
      "  Outlook = Overcast\n",
      "      [Class: Yes]\n",
      "  Outlook = Rain\n",
      "    Wind\n",
      "      Wind = Strong\n",
      "          [Class: No]\n",
      "      Wind = Weak\n",
      "          [Class: Yes]\n",
      "  Outlook = Sunny\n",
      "    Humidity\n",
      "      Humidity = High\n",
      "          [Class: No]\n",
      "      Humidity = Normal\n",
      "          [Class: Yes]\n",
      "\n",
      "Classification Report:\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5 0]\n",
      " [0 9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def importData(path='tennis.csv'):\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "def entropy(data):\n",
    "    target_values = data.iloc[:, -1].value_counts(normalize=True)\n",
    "    entropy_val = -sum(target_values * np.log2(target_values))\n",
    "    return entropy_val\n",
    "\n",
    "def information_gain_ratio(data, attribute):\n",
    "    # Calculate information gain\n",
    "    entropy_before_split = entropy(data)\n",
    "    values, counts = np.unique(data[attribute], return_counts=True)\n",
    "    weighted_entropy_after_split = sum([(counts[i] / len(data)) * entropy(data[data[attribute] == values[i]]) for i in range(len(values))])\n",
    "    information_gain = entropy_before_split - weighted_entropy_after_split\n",
    "\n",
    "    # Calculate split information\n",
    "    split_info = -sum((counts[i] / len(data)) * np.log2(counts[i] / len(data)) for i in range(len(values)))\n",
    "\n",
    "    # Calculate information gain ratio\n",
    "    if split_info == 0:\n",
    "        return 0  # To avoid division by zero\n",
    "    information_gain_ratio_val = information_gain / split_info\n",
    "\n",
    "    return information_gain_ratio_val\n",
    "\n",
    "def choose_attribute(data, attributes):\n",
    "    information_gain_ratios = [information_gain_ratio(data, attribute) for attribute in attributes]\n",
    "    best_attribute_index = np.argmax(information_gain_ratios)\n",
    "    return attributes[best_attribute_index]\n",
    "\n",
    "def split_data(data, attribute, value):\n",
    "    return data[data[attribute] == value]\n",
    "\n",
    "def majority_class(data):\n",
    "    return data.iloc[:, -1].mode()[0]\n",
    "\n",
    "def build_tree(data, attributes):\n",
    "    # If all instances have the same class label, return a leaf node with that class label\n",
    "    if len(np.unique(data.iloc[:, -1])) == 1:\n",
    "        return data.iloc[0, -1]\n",
    "\n",
    "    # If there are no more attributes to split on, return the majority class label\n",
    "    if len(attributes) == 0:\n",
    "        return majority_class(data)\n",
    "\n",
    "    # Choose the best attribute to split on\n",
    "    best_attribute = choose_attribute(data, attributes)\n",
    "\n",
    "    # Create a new decision tree node with the best attribute\n",
    "    tree = {best_attribute: {}}\n",
    "\n",
    "    # Remove the best attribute from the list of attributes\n",
    "    attributes = [attr for attr in attributes if attr != best_attribute]\n",
    "\n",
    "    # Split the dataset based on the values of the best attribute\n",
    "    for value in np.unique(data[best_attribute]):\n",
    "        sub_data = split_data(data, best_attribute, value)\n",
    "        subtree = build_tree(sub_data, attributes)\n",
    "        tree[best_attribute][value] = subtree\n",
    "\n",
    "    return tree\n",
    "\n",
    "def print_tree(tree, depth=0):\n",
    "    if isinstance(tree, dict):\n",
    "        for attribute, subtree in tree.items():\n",
    "            print('  ' * depth + attribute)\n",
    "            for value, sub_tree in subtree.items():\n",
    "                print('  ' * (depth+1) + '{} = {}'.format(attribute, value))\n",
    "                print_tree(sub_tree, depth + 2)\n",
    "    else:\n",
    "        print('  ' * depth + '  [Class: ' + str(tree) + ']')\n",
    "\n",
    "def predict(tree, instance):\n",
    "    # Recursively traverse the tree to make predictions\n",
    "    for attribute, subtree in tree.items():\n",
    "        value = instance[attribute]\n",
    "        if value in subtree:\n",
    "            # If the attribute value exists in the subtree, traverse deeper\n",
    "            if isinstance(subtree[value], dict):\n",
    "                return predict(subtree[value], instance)\n",
    "            else:\n",
    "                return subtree[value]  # Return the predicted class label\n",
    "        else:\n",
    "            # If the attribute value is not found in the subtree, return the majority class\n",
    "            return majority_class(data)\n",
    "\n",
    "def evaluate_predictions(data, tree):\n",
    "    predicted_labels = [predict(tree, instance) for _, instance in data.iterrows()]\n",
    "    actual_labels = data.iloc[:, -1]\n",
    "    return actual_labels, predicted_labels\n",
    "\n",
    "def classification_report(actual_labels, predicted_labels):\n",
    "    true_positives = sum(1 for a, p in zip(actual_labels, predicted_labels) if a == p)\n",
    "    false_positives = sum(1 for a, p in zip(actual_labels, predicted_labels) if a != p)\n",
    "    accuracy = true_positives / len(actual_labels)\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / len(actual_labels)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score\n",
    "    }\n",
    "\n",
    "# Load the dataset\n",
    "data = importData('tennis.csv')\n",
    "\n",
    "# Get list of attribute names\n",
    "attributes = list(data.columns[:-1])\n",
    "\n",
    "# Build the decision tree using C4.5 algorithm\n",
    "tree = build_tree(data, attributes)\n",
    "\n",
    "# Print the decision tree\n",
    "print_tree(tree)\n",
    "\n",
    "# Evaluate the model\n",
    "actual_labels, predicted_labels = evaluate_predictions(data, tree)\n",
    "\n",
    "# Compute classification report\n",
    "report = classification_report(actual_labels, predicted_labels)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"Accuracy:\", report['accuracy'])\n",
    "print(\"Precision:\", report['precision'])\n",
    "print(\"Recall:\", report['recall'])\n",
    "print(\"F1 Score:\", report['f1_score'])\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(actual_labels, predicted_labels)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
