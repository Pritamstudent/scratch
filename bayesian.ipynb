{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "columns = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"num\"]\n",
    "data = pd.read_csv(url, names=columns)\n",
    "\n",
    "# Preprocess the dataset\n",
    "# Replace missing values with the median of the column\n",
    "data = data.replace('?', pd.NA)\n",
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "data = data.fillna(data.median())\n",
    "\n",
    "# Binarize the target variable: presence (1) or absence (0) of heart disease\n",
    "data['num'] = data['num'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop('num', axis=1)\n",
    "y = data['num']\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "for column in X.select_dtypes(include=['object']).columns:\n",
    "    X[column] = label_encoder.fit_transform(X[column])\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAN structure edges: [(0, 7), (7, 6), (0, 3), (3, 2), (2, 8), (2, 12), (2, 4), (0, 11), (8, 9), (12, 1), (9, 10), (6, 5)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import numpy as np\n",
    "\n",
    "def compute_mutual_info(X, y):\n",
    "    \"\"\"Compute mutual information between features and the target variable.\"\"\"\n",
    "    mutual_info = mutual_info_classif(X, y.astype(int))  # Ensure y is treated as discrete\n",
    "    return mutual_info\n",
    "\n",
    "def create_tan_structure(X, y):\n",
    "    \"\"\"Create the TAN structure based on mutual information.\"\"\"\n",
    "    n_features = X.shape[1]\n",
    "    mutual_info = compute_mutual_info(X, y)\n",
    "\n",
    "    # Create the adjacency matrix for the TAN structure\n",
    "    adj_matrix = np.zeros((n_features, n_features))\n",
    "\n",
    "    # Compute mutual information between features\n",
    "    for i in range(n_features):\n",
    "        for j in range(i + 1, n_features):\n",
    "            adj_matrix[i, j] = mutual_info_classif(X[:, i].reshape(-1, 1), X[:, j].astype(int))  # Treat X[:, j] as discrete\n",
    "            adj_matrix[j, i] = adj_matrix[i, j]\n",
    "\n",
    "    # Select the maximum spanning tree using Prim's algorithm\n",
    "    selected = [False] * n_features\n",
    "    selected[0] = True\n",
    "    edges = []\n",
    "\n",
    "    for _ in range(n_features - 1):\n",
    "        max_weight = -1\n",
    "        max_edge = (-1, -1)\n",
    "        for i in range(n_features):\n",
    "            if selected[i]:\n",
    "                for j in range(n_features):\n",
    "                    if not selected[j] and adj_matrix[i, j] > max_weight:\n",
    "                        max_weight = adj_matrix[i, j]\n",
    "                        max_edge = (i, j)\n",
    "        edges.append(max_edge)\n",
    "        selected[max_edge[1]] = True\n",
    "\n",
    "    return edges\n",
    "\n",
    "tan_edges = create_tan_structure(X_train, y_train)\n",
    "print(\"TAN structure edges:\", tan_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional probabilities: defaultdict(<class 'dict'>, {(0, 7): {(0, 0): 0.0, (0, 1): 0.0, (1, 0): 0.0, (1, 1): 0.0}, (7, 6): {(0, 0): 0.0, (0, 1): 0.0, (1, 0): 0.0, (1, 1): 0.0}, (0, 3): {(0, 0): 0.0, (0, 1): 0.0, (1, 0): 0.0, (1, 1): 0.0}, (3, 2): {(0, 0): 0.0, (0, 1): 0.0, (1, 0): 0.0, (1, 1): 0.0}, (2, 8): {(0, 0): 0.0, (0, 1): 0.0, (1, 0): 0.0, (1, 1): 0.0}, (2, 12): {(0, 0): 0.0, (0, 1): 0.0, (1, 0): 0.0, (1, 1): 0.0}, (2, 4): {(0, 0): 0.0, (0, 1): 0.0, (1, 0): 0.0, (1, 1): 0.0}, (0, 11): {(0, 0): 0.0, (0, 1): 0.0, (1, 0): 0.0, (1, 1): 0.0}, (8, 9): {(0, 0): 0.0, (0, 1): 0.0, (1, 0): 0.0, (1, 1): 0.0}, (12, 1): {(0, 0): 0.0, (0, 1): 0.0, (1, 0): 0.0, (1, 1): 0.0}, (9, 10): {(0, 0): 0.0, (0, 1): 0.0, (1, 0): 0.0, (1, 1): 0.0}, (6, 5): {(0, 0): 0.0, (0, 1): 0.0, (1, 0): 0.0, (1, 1): 0.0}})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def compute_conditional_probabilities(X, y, edges):\n",
    "    \"\"\"Compute conditional probabilities for the TAN structure.\"\"\"\n",
    "    n_features = X.shape[1]\n",
    "    conditional_probs = defaultdict(dict)\n",
    "\n",
    "    for (i, j) in edges:\n",
    "        for val_i in [0, 1]:\n",
    "            for val_j in [0, 1]:\n",
    "                subset = X[(X[:, i] == val_i) & (X[:, j] == val_j)]\n",
    "                conditional_probs[(i, j)][(val_i, val_j)] = len(subset) / len(X)\n",
    "\n",
    "    return conditional_probs\n",
    "\n",
    "conditional_probs = compute_conditional_probabilities(X_train, y_train, tan_edges)\n",
    "print(\"Conditional probabilities:\", conditional_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 47.54%\n"
     ]
    }
   ],
   "source": [
    "def infer_heart_disease(X_test, conditional_probs, tan_edges):\n",
    "    \"\"\"Infer the presence of heart disease using the TAN structure.\"\"\"\n",
    "    predictions = []\n",
    "\n",
    "    for x in X_test:\n",
    "        probs = {0: 1.0, 1: 1.0}\n",
    "\n",
    "        for (i, j) in tan_edges:\n",
    "            val_i = x[i]\n",
    "            val_j = x[j]\n",
    "            probs[0] *= conditional_probs[(i, j)].get((val_i, val_j), 1e-6)\n",
    "            probs[1] *= conditional_probs[(i, j)].get((val_i, val_j), 1e-6)\n",
    "\n",
    "        if probs[1] > probs[0]:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "predictions = infer_heart_disease(X_test, conditional_probs, tan_edges)\n",
    "\n",
    "# Evaluate the performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
