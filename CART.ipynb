{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importData(path = 'tennis.csv'):\n",
    "\n",
    "    data = pd.read_csv(path, header =0 , skiprows = 0)\n",
    "    print(data.head())\n",
    "    data.target  =data['Play']\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(data):\n",
    "\n",
    "    d = data.iloc[:,-1]\n",
    "    d= d.value_counts()\n",
    "    s = 0\n",
    "    for v in d.keys():\n",
    "        p = d[v]/sum(d)\n",
    "        s-=p*np.log2(p)\n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def values(attr):\n",
    "    l = []\n",
    "    for x in attr:\n",
    "        if x not in l:\n",
    "            l.append(x)\n",
    "    return l\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IG(data, A):\n",
    "\n",
    "    Es = entropy(data)\n",
    "    val = values(data[A])\n",
    "    s_c = data[A].value_counts()\n",
    "    s_v = []\n",
    "\n",
    "    for v in range(len(val)):\n",
    "        ds = data[data[A] == val[v]]\n",
    "        s = 0\n",
    "        for res in values(data.iloc[:,-1]):\n",
    "            try:\n",
    "                pi = ds.iloc[:,-1].value_counts()[res]/len(ds)\n",
    "                s -= pi*np.log2(pi)\n",
    "            except:\n",
    "                s = 0\n",
    "        s_v.append(s)\n",
    "    for i in range(len(val)):\n",
    "        Es = Es - s_c[val[i]]*s_v[i]/sum(s_c)\n",
    "        \n",
    "    return Es\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "\n",
    "    def __init__(self, name = None, attr = None):\n",
    "        self.name = name\n",
    "        self.attr = attr\n",
    "    def call_(self):\n",
    "        return self.name\n",
    "\n",
    "def DTNode(data, features_used):\n",
    "    node = Node()\n",
    "    IGmax = 0\n",
    "    vbest = None\n",
    "    val_list = [ v for v in values(data)[:-1] if v not in features_used]\n",
    "\n",
    "    if val_list != []:\n",
    "\n",
    "        for v in val_list:\n",
    "\n",
    "            if IG(data, v) > IGmax:\n",
    "                IGmax = IG(data, v)\n",
    "                v_best = v\n",
    "        if v_best:\n",
    "            features_used.append(v_best)\n",
    "            node.name = v_best\n",
    "            node.attr = values(data[v_best])\n",
    "            return node\n",
    "        else:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def DTC(data, features_used):\n",
    "    root = DTNode(data, features_used)\n",
    "    DT_dict = {}\n",
    "    if root != None:\n",
    "        item = []\n",
    "        for attr in root.attr:\n",
    "            dataN = data[data[root.name] == attr]\n",
    "            if entropy(dataN) == 0:\n",
    "                item.append((attr, values(dataN.iloc[:, -1])[0]))\n",
    "            else:\n",
    "                dt = DTC(dataN, features_used)\n",
    "                item.append((attr, dt))\n",
    "        DT_dict[root.name] = item\n",
    "    return DT_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Outlook Temperature Humidity    Wind Play\n",
      "0     Sunny         Hot     High    Weak   No\n",
      "1     Sunny         Hot     High  Strong   No\n",
      "2  Overcast         Hot     High    Weak  Yes\n",
      "3      Rain        Mild     High    Weak  Yes\n",
      "4      Rain        Cool   Normal    Weak  Yes\n",
      "{'Outlook': [('Sunny', {'Humidity': [('High', 'No'), ('Normal', 'Yes')]}), ('Overcast', 'Yes'), ('Rain', {'Wind': [('Weak', 'Yes'), ('Strong', 'No')]})]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GOD WORLD\\AppData\\Local\\Temp\\ipykernel_17268\\3160606400.py:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  data.target  =data['Play']\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = importData('tennis.csv')\n",
    "\n",
    "# Initialize the list to keep track of features used\n",
    "features_used = []\n",
    "\n",
    "# Build the decision tree using the ID3 algorithm\n",
    "decision_tree = DTC(data, features_used)\n",
    "\n",
    "# Print or visualize the decision tree\n",
    "print(decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X1 = Rain]\n",
      " [X1 = Overcast]\n",
      "  [Yes]\n",
      "  [Yes]\n",
      " [X3 = Normal]\n",
      "  [X1 = Sunny]\n",
      "   [No]\n",
      "   [No]\n",
      "  [X4 = Weak]\n",
      "   [No]\n",
      "   [Yes]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def importData(path='tennis.csv'):\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "def gini_index(groups, classes):\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val) / size\n",
    "            score += p * p\n",
    "        gini += (1.0 - score) * (size / n_instances)\n",
    "    return gini\n",
    "\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    "\n",
    "def get_split(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            if gini < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "    return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth+1)\n",
    "\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n",
    "\n",
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        if isinstance(node['value'], str):\n",
    "            print('%s[X%d = %s]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "        else:\n",
    "            print('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), float(node['value']))))\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth*' ', node)))\n",
    "\n",
    "# Load the dataset\n",
    "data = importData('tennis.csv')\n",
    "dataset = data.values.tolist()\n",
    "\n",
    "# Define the maximum depth of the tree and the minimum number of samples required to split a node\n",
    "max_depth = 3\n",
    "min_size = 2\n",
    "\n",
    "# Build the CART decision tree\n",
    "tree = build_tree(dataset, max_depth, min_size)\n",
    "\n",
    "# Print the constructed decision tree\n",
    "print_tree(tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define the data\n",
    "data = {\n",
    "    'a1': ['x', 'x', 'x', 'y', 'y', 'x', 'x', 'y', 'x', 'x', 'y', 'x'],\n",
    "    'a2': ['u', 'u', 'u', 'u', 'v', 'v', 'u', 'v', 'u', 'w', 'w', 'w'],\n",
    "    'a3': ['n', 'p', 'n', 'n', 'n', 'n', 'p', 'm', 'n', 'p', 'n', 'n'],\n",
    "    'a4': ['e', 'f', 'g', 'e', 'f', 'e', 'e', 'f', 'f', 'f', 'f', 'g'],\n",
    "    'Class': ['+', '+', '+', '+', '-', '+', '-', '+', '+', '+', '-', '+']\n",
    "}\n",
    "data1 = {\n",
    "    'Day': [f'D{i}' for i in range(1, 15)],\n",
    "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],\n",
    "    'Temperature (oF)': [85, 80, 83, 70, 68, 65, 64, 72, 69, 75, 75, 72, 81, 71],\n",
    "    'Humidity (%)': [85, 90, 86, 96, 80, 70, 65, 95, 70, 80, 70, 90, 75, 91],\n",
    "    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Strong'],\n",
    "    'PlayTennis': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "data = pd.DataFrame(data)\n",
    "# Create DataFrame\n",
    "data1 = pd.DataFrame(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X1 = y]\n",
      " [X3 = p]\n",
      "  [X1 = x]\n",
      "   [+]\n",
      "   [+]\n",
      "  [X4 = f]\n",
      "   [-]\n",
      "   [+]\n",
      " [X2 = v]\n",
      "  [+]\n",
      "  [X3 = n]\n",
      "   [+]\n",
      "   [-]\n",
      "[X2 = Rain]\n",
      " [X1 = D3]\n",
      "  [Yes]\n",
      "  [Yes]\n",
      " [X4 < 85.000]\n",
      "  [X3 < 68.000]\n",
      "   [No]\n",
      "   [Yes]\n",
      "  [X3 < 71.000]\n",
      "   [Yes]\n",
      "   [No]\n"
     ]
    }
   ],
   "source": [
    "dataset = data.values.tolist()\n",
    "dataset1 = data1.values.tolist()\n",
    "# Define the maximum depth of the tree and the minimum number of samples required to split a node\n",
    "max_depth = 3\n",
    "min_size = 2\n",
    "\n",
    "# Build the CART decision tree\n",
    "tree = build_tree(dataset, max_depth, min_size)\n",
    "tree1 = build_tree(dataset1, max_depth, min_size)\n",
    "# Print the constructed decision tree\n",
    "print_tree(tree)\n",
    "print_tree(tree1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X1 = Rain]\n",
      " [X1 = Overcast]\n",
      "  [Yes]\n",
      "  [Yes]\n",
      " [X3 = Normal]\n",
      "  [X1 = Sunny]\n",
      "   [No]\n",
      "   [No]\n",
      "  [X4 = Weak]\n",
      "   [No]\n",
      "   [Yes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "Accuracy: 0.8571428571428571\n",
      "Precision: 0.8571428571428571\n",
      "Recall: 0.8571428571428571\n",
      "F1 Score: 0.8571428571428571\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5 0]\n",
      " [2 7]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def importData(path='tennis.csv'):\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "def gini_index(groups, classes):\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val) / size\n",
    "            score += p * p\n",
    "        gini += (1.0 - score) * (size / n_instances)\n",
    "    return gini\n",
    "\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    "\n",
    "def get_split(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            if gini < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "    return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth+1)\n",
    "\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n",
    "\n",
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        if isinstance(node['value'], str):\n",
    "            print('%s[X%d = %s]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "        else:\n",
    "            print('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), float(node['value']))))\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth*' ', node)))\n",
    "\n",
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "\n",
    "def get_predictions(tree, dataset):\n",
    "    predictions = []\n",
    "    for row in dataset:\n",
    "        prediction = predict(tree, row)\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "def classification_report(actual, predicted):\n",
    "    true_positives = sum(1 for a, p in zip(actual, predicted) if a == p)\n",
    "    false_positives = sum(1 for a, p in zip(actual, predicted) if a != p)\n",
    "    accuracy = true_positives / len(actual)\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / len(actual)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score\n",
    "    }\n",
    "\n",
    "# Load the dataset\n",
    "data = importData('tennis.csv')\n",
    "dataset = data.values.tolist()\n",
    "\n",
    "# Define the maximum depth of the tree and the minimum number of samples required to split a node\n",
    "max_depth = 3\n",
    "min_size = 2\n",
    "\n",
    "# Build the CART decision tree\n",
    "tree = build_tree(dataset, max_depth, min_size)\n",
    "\n",
    "# Print the constructed decision tree\n",
    "print_tree(tree)\n",
    "\n",
    "# Get the actual labels from the dataset\n",
    "actual_labels = [row[-1] for row in dataset]\n",
    "\n",
    "# Get predictions from the decision tree\n",
    "predicted_labels = get_predictions(tree, dataset)\n",
    "\n",
    "# Compute classification report\n",
    "report = classification_report(actual_labels, predicted_labels)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"Accuracy:\", report['accuracy'])\n",
    "print(\"Precision:\", report['precision'])\n",
    "print(\"Recall:\", report['recall'])\n",
    "print(\"F1 Score:\", report['f1_score'])\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(actual_labels, predicted_labels)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
